{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZ8O-jZb_VB8",
    "tags": []
   },
   "source": [
    "# US EPA Air Quality System AQI Data Acquisition and Processing \n",
    "The code below illustrates how to request data from the US Environmental Protection Agency (EPA) Air Quality Service (AQS) API. This is a historical API and does not provide real-time air quality data. The [documentation](https://aqs.epa.gov/aqsweb/documents/data_api.html) for the API provides definitions of the different call parameter and examples of the various calls that can be made to the API.\n",
    "\n",
    "This notebook works systematically through calls, requesting an API key, using 'list' to get various IDs and parameter values, and using 'daily summary' to get summary data that meets specific conditions. \n",
    "\n",
    "The US EPA was created in the early 1970's. The EPA reports that they only started broad based monitoring with standardized quality assurance procedures in the 1980's. Many counties will have data starting somewhere between 1983 and 1988. Specifically, my county Maricopa (for assigned city Mesa, AZ) has data starting from 1965. Some [additional information on the Air Quality System can be found in the EPA FAQ](https://www.epa.gov/outdoor-air-quality-data/frequent-questions-about-airdata) on the system.\n",
    "\n",
    "The AQI index is meant to tell us something about how healthy or clean the air is on any day. The AQI is actually a somewhat complext measure. When I started this example I looked up [how to calculate the AQI](https://www.airnow.gov/sites/default/files/2020-05/aqi-technical-assistance-document-sept2018.pdf) so that I would know roughly what goes into that value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### License\n",
    "A lot of the code/ markdown text below was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.1 - August 16, 2024.\n",
    "\n",
    "I have made slight modifications to the code as required for my project, and also added some extra code for the creation of my dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the Google Colab Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yM5bfjiQ_oul",
    "outputId": "08df5837-3830-46a9-8cbd-fbb765f3ff08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i0uHP356_xel",
    "outputId": "66bb85cf-5607-45d8-a698-cef142ead95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Data 512/Project\n"
     ]
    }
   ],
   "source": [
    "%cd \"drive/MyDrive/Data 512/Project/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "First we start with some imports and some constant definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You will need to install any dependencies you don't have. For this, you will require pip/pip3 if you do not already have it.\n",
    "After installing pip, you can run: !pip install {package name} to install any required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W4y3woV8_VCC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    These are standard python modules\n",
    "#\n",
    "import json, time\n",
    "#\n",
    "#    The 'requests' module is a distribution module for making web requests. If you do not have it already, you'll need to install it\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WdpHl95J_VCE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#\n",
    "#    This is the root of all AQS API URLs\n",
    "#\n",
    "API_REQUEST_URL = 'https://aqs.epa.gov/data/api'\n",
    "\n",
    "#\n",
    "#    These are some of the 'actions' we can ask the API to take or requests that we can make of the API\n",
    "#\n",
    "#    Sign-up request - generally only performed once - unless you lose your key\n",
    "API_ACTION_SIGNUP = '/signup?email={email}'\n",
    "#\n",
    "#    List actions provide information on API parameter values that are required by some other actions/requests\n",
    "API_ACTION_LIST_CLASSES = '/list/classes?email={email}&key={key}'\n",
    "API_ACTION_LIST_PARAMS = '/list/parametersByClass?email={email}&key={key}&pc={pclass}'\n",
    "API_ACTION_LIST_SITES = '/list/sitesByCounty?email={email}&key={key}&state={state}&county={county}'\n",
    "#\n",
    "#    Monitor actions are requests for monitoring stations that meet specific criteria\n",
    "API_ACTION_MONITORS_COUNTY = '/monitors/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_MONITORS_BOX = '/monitors/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    Summary actions are requests for summary data. These are for daily summaries\n",
    "API_ACTION_DAILY_SUMMARY_COUNTY = '/dailyData/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_DAILY_SUMMARY_BOX = '/dailyData/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    It is always nice to be respectful of a free data resource.\n",
    "#    We're going to observe a 100 requests per minute limit - which is fairly nice\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "#\n",
    "#\n",
    "#    This is a template that covers most of the parameters for the actions we might take, from the set of actions\n",
    "#    above. In the examples below, most of the time parameters can either be supplied as individual values to a\n",
    "#    function - or they can be set in a copy of the template and passed in with the template.\n",
    "#\n",
    "AQS_REQUEST_TEMPLATE = {\n",
    "    \"email\":      \"\",\n",
    "    \"key\":        \"\",\n",
    "    \"state\":      \"\",     # the two digit state FIPS # as a string\n",
    "    \"county\":     \"\",     # the three digit county FIPS # as a string\n",
    "    \"begin_date\": \"\",     # the start of a time window in YYYYMMDD format\n",
    "    \"end_date\":   \"\",     # the end of a time window in YYYYMMDD format, begin_date and end_date must be in the same year\n",
    "    \"minlat\":    0.0,\n",
    "    \"maxlat\":    0.0,\n",
    "    \"minlon\":    0.0,\n",
    "    \"maxlon\":    0.0,\n",
    "    \"param\":     \"\",     # a list of comma separated 5 digit codes, max 5 codes requested\n",
    "    \"pclass\":    \"\"      # parameter class is only used by the List calls\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTMIuUeG_VCF"
   },
   "source": [
    "**Step 1:** Making a sign-up request\n",
    "\n",
    "Before we use the API you need to request a key. You will use an email address to make the request. The EPA then sends a confirmation email link and a 'key' that you use for all other requests.\n",
    "\n",
    "You only need to sign-up once, unless you want to invalidate your current key (by getting a new key) or you lose your key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FluOTfzz_VCF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the sign-up request. The parameters are standardized so that this function definition matches\n",
    "#    all of the others. However, the easiest way to call this is to simply call this function with your preferred\n",
    "#    email address.\n",
    "#\n",
    "def request_signup(email_address = None,\n",
    "                   endpoint_url = API_REQUEST_URL,\n",
    "                   endpoint_action = API_ACTION_SIGNUP,\n",
    "                   request_template = AQS_REQUEST_TEMPLATE,\n",
    "                   headers = None):\n",
    "\n",
    "    # Make sure we have a string - if you don't have access to this email addres, things might go badly for you\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_signup()'\")\n",
    "\n",
    "    if '@' not in request_template['email']:\n",
    "        raise Exception(f\"Must supply an email address to call 'request_signup()'. The string '{request_template['email']}' does not look like an email address.\")\n",
    "\n",
    "    # Compose the signup url - create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pz665PcX_VCG",
    "outputId": "db44e87d-f716-4308-a3ad-28dde6598c35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting SIGNUP ...\n",
      "{\n",
      "    \"Header\": [\n",
      "        {\n",
      "            \"status\": \"Success\",\n",
      "            \"request_time\": \"2024-10-29T16:40:10-04:00\",\n",
      "            \"url\": \"https://aqs.epa.gov/data/api/signup?email=gmihir@uw.edu\"\n",
      "        }\n",
      "    ],\n",
      "    \"Data\": [\n",
      "        \"You should receive a registration confirmation email with a link for confirming your email shortly.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#    A SIGNUP request is only to be done once, to request a key. A key is sent to that email address and needs to be confirmed with a click through\n",
    "#    This code should probably be commented out after you've made your key request to make sure you don't accidentally make a new sign-up request\n",
    "#\n",
    "print(\"Requesting SIGNUP ...\")\n",
    "USERNAME = \"gmihir@uw.edu\" # Replace with your email address\n",
    "response = request_signup(USERNAME)\n",
    "print(json.dumps(response,indent=4))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-v0EXLHm_VCI"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   Once we have the signup email, we can define two constants:\n",
    "#\n",
    "#   USERNAME - This should be the email address you sent the EPA asking for access to the API during sign-up\n",
    "#   APIKEY   - This should be the authorization key they sent you\n",
    "#\n",
    "#\n",
    "USERNAME = \"gmihir@uw.edu\" # Replace with the email address you signed up with.\n",
    "APIKEY = \"\" # Add the API key provided in your email. (Don't forget to confirm your account from the email)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ7qHtVb_VCJ"
   },
   "source": [
    "**Step 2:** Making a list request\n",
    "\n",
    "Once you have a key, the next thing is to get information about the different types of air quality monitoring (sensors) and the different places where we might find air quality stations. The monitoring system is complex and changes all the time. The EPA implementation allows an API user to find changes to monitoring sites and sensors by making requests - maybe monthly, or daily. This API approach is probably better than having the EPA publish documentation that may be out of date as soon as it hits a web page. The one problem here is that some of the responses rely on jargon or terms-of-art. That is, one needs to know a bit about the way atmospheric sciece works to understand some of the terms. ... Good thing we can use the web to search for terms we don't know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Lpfddhvq_VCK"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the list request. There are several versions of the list request that only require email and key.\n",
    "#    This code sets the default action/requests to list the groups or parameter class descriptors. Having those descriptors\n",
    "#    allows one to request the individual (proprietary) 5 digit codes for individual air quality measures by using the\n",
    "#    param request. Some code in later cells will illustrate those requests.\n",
    "#\n",
    "def request_list_info(email_address = None, key = None,\n",
    "                      endpoint_url = API_REQUEST_URL,\n",
    "                      endpoint_action = API_ACTION_LIST_CLASSES,\n",
    "                      request_template = AQS_REQUEST_TEMPLATE,\n",
    "                      headers = None):\n",
    "\n",
    "    #  Make sure we have email and key - at least\n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "\n",
    "    # For the basic request we need an email address and a key\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_list_info()'\")\n",
    "    if not request_template['key']:\n",
    "        raise Exception(\"Must supply a key to call 'request_list_info()'\")\n",
    "\n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcVLMbPt_VCL",
    "outputId": "c232095f-0f2b-4241-b263-f1a4340b1e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"AIRNOW MAPS\",\n",
      "        \"value_represented\": \"The parameters represented on AirNow maps (88101, 88502, and 44201)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"ALL\",\n",
      "        \"value_represented\": \"Select all Parameters Available\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"AQI POLLUTANTS\",\n",
      "        \"value_represented\": \"Pollutants that have an AQI Defined\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CORE_HAPS\",\n",
      "        \"value_represented\": \"Urban Air Toxic Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CRITERIA\",\n",
      "        \"value_represented\": \"Criteria Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CSN DART\",\n",
      "        \"value_represented\": \"List of CSN speciation parameters to populate the STI DART tool\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"FORECAST\",\n",
      "        \"value_represented\": \"Parameters routinely extracted by AirNow (STI)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"HAPS\",\n",
      "        \"value_represented\": \"Hazardous Air Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"IMPROVE CARBON\",\n",
      "        \"value_represented\": \"IMPROVE Carbon Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"IMPROVE_SPECIATION\",\n",
      "        \"value_represented\": \"PM2.5 Speciated Parameters Measured at IMPROVE sites\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"MET\",\n",
      "        \"value_represented\": \"Meteorological Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"NATTS CORE HAPS\",\n",
      "        \"value_represented\": \"The core list of toxics of interest to the NATTS program.\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"NATTS REQUIRED\",\n",
      "        \"value_represented\": \"Required compounds to be collected in the National Air Toxics Network\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PAMS\",\n",
      "        \"value_represented\": \"Photochemical Assessment Monitoring System\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PAMS_VOC\",\n",
      "        \"value_represented\": \"Volatile Organic Compound subset of the PAMS Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM COARSE\",\n",
      "        \"value_represented\": \"PM between 2.5 and 10 micrometers\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM10 SPECIATION\",\n",
      "        \"value_represented\": \"PM10 Speciated Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM2.5 CONT NONREF\",\n",
      "        \"value_represented\": \"PM2.5 Continuous, Nonreference Methods\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM2.5 MASS/QA\",\n",
      "        \"value_represented\": \"PM2.5 Mass and QA Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SCHOOL AIR TOXICS\",\n",
      "        \"value_represented\": \"School Air Toxics Program Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION\",\n",
      "        \"value_represented\": \"PM2.5 Speciated Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION CARBON\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Carbon Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION CATION/ANION\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Cation/Anion Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION METALS\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Metal Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"UATMP CARBONYL\",\n",
      "        \"value_represented\": \"Urban Air Toxics Monitoring Program Carbonyls\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"UATMP VOC\",\n",
      "        \"value_represented\": \"Urban Air Toxics Monitoring Program VOCs\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"VOC\",\n",
      "        \"value_represented\": \"Volatile organic compounds\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   The default should get us a list of the various groups or classes of sensors. These classes are user defined names for clustors of\n",
    "#   sensors that might be part of a package or default air quality sensing station. We need a class name to start getting down to the\n",
    "#   a sensor ID. Each sensor type has an ID number. We'll eventually need those ID numbers to be able to request values that come from\n",
    "#   that specific sensor.\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "\n",
    "response = request_list_info(request_template=request_data)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmpfZl15_VCL"
   },
   "source": [
    "We're interested in getting to something that might be the Air Quality Index (AQI). You see this reported on the news - often around smog values, but also when there is smoke in the sky. The AQI is a complex measure of different gasses and of the particles in the air (dust, dirt, ash ...).\n",
    "\n",
    "From the list produced by our 'list/Classes' request above, it looks like there is a class of sensors called \"AQI POLLUTANTS\". Let's try to get a list of those specific sensors and see what we can get from those.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VMfzygvf_VCL"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   Once we have a list of the classes or groups of possible sensors, we can find the sensor IDs that make up that class (group)\n",
    "#   The one that looks to be associated with the Air Quality Index is \"AQI POLLUTANTS\"\n",
    "#   We'll use that to make another list request.\n",
    "#\n",
    "AQI_PARAM_CLASS = \"AQI POLLUTANTS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXaHqpIE_VCM",
    "outputId": "f7354717-ad16-4cbd-f79f-1389a23f4d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"42101\",\n",
      "        \"value_represented\": \"Carbon monoxide\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"42401\",\n",
      "        \"value_represented\": \"Sulfur dioxide\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"42602\",\n",
      "        \"value_represented\": \"Nitrogen dioxide (NO2)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"44201\",\n",
      "        \"value_represented\": \"Ozone\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"81102\",\n",
      "        \"value_represented\": \"PM10 Total 0-10um STP\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"88101\",\n",
      "        \"value_represented\": \"PM2.5 - Local Conditions\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"88502\",\n",
      "        \"value_represented\": \"Acceptable PM2.5 AQI & Speciation Mass\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   Structure a request to get the sensor IDs associated with the AQI\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['pclass'] = AQI_PARAM_CLASS  # here we specify that we want this 'pclass' or parameter classs\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_PARAMS)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYG5pwab_VCM"
   },
   "source": [
    "We should now have (above) a response containing a set of sensor ID numbers. The list should include the sensor numbers as well as a description or name for each sensor.\n",
    "\n",
    "The EPA AQS API has limits on some call parameters. Specifically, when we request data for sensors we can only specify a maximum of 5 different sensor values to return. This means we cannot get all of the Air Quality Index parameters in one request for data. We have to break it up.\n",
    "\n",
    "What I did below was to break the request into two logical groups, the AQI sensors that sample gasses and the AQI sensors that sample particles in the air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2RIMv835_VCM"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   Given the set of sensor codes, now we can create a parameter list or 'param' value as defined by the AQS API spec.\n",
    "#   It turns out that we want all of these measures for AQI, but we need to have two different param constants to get\n",
    "#   all seven of the code types. We can only have a max of 5 sensors/values request per param.\n",
    "#\n",
    "#   Gaseous AQI pollutants CO, SO2, NO2, and O2\n",
    "AQI_PARAMS_GASEOUS = \"42101,42401,42602,44201\"\n",
    "#\n",
    "#   Particulate AQI pollutants PM10, PM2.5, and Acceptable PM2.5\n",
    "AQI_PARAMS_PARTICULATES = \"81102,88101,88502\"\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKjSTfFX_VCN"
   },
   "source": [
    "Air quality monitoring stations are located all over the US at different locations.\n",
    "\n",
    "This list includes the [FIPS](https://www.census.gov/library/reference/code-lists/ansi.html) number for the state and county as a 5 digit string. This format, the 5 digit string, is a 'old' format that is still widely used. There are new codes that may eventually be adopted for the US government information systems. But FIPS is currently what the AQS uses, so that's what is in the list as the constant.\n",
    "\n",
    "For my assigned city Mesa, AZ, the county is Maricopa, and the fips code is 04013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EHikWRrO_VCN"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   We store the information about my assigned city in city_locations\n",
    "#\n",
    "CITY_LOCATIONS = {\n",
    "    'Mesa' :       {'city'   : 'Mesa',\n",
    "                       'county' : 'Maricopa',\n",
    "                       'state'  : 'Arizona',\n",
    "                       'fips'   : '04013',\n",
    "                       'latlon' : [33.40, -111.72] },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVP1ul96_VCN"
   },
   "source": [
    "Given our CITY_LOCATIONS constant we can now find which monitoring locations are nearby. One option is to use the county to define the area we're interest in. You can get the EPA to list their monitoring stations by county. You can also get a set of monitoring stations by using a bounding box of latitude, longitude points. For my purpose, the county approach gave me enough stations and data, resulting in me not using the bounding box approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PBWLTujK_VCN",
    "outputId": "200cfe02-e88f-477b-a8ed-eddead1a4d2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"0013\",\n",
      "        \"value_represented\": \"Old South Phoenix Site\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0015\",\n",
      "        \"value_represented\": \"Emergency Management\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0016\",\n",
      "        \"value_represented\": \"WEST INDIAN SCHOOL RD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0019\",\n",
      "        \"value_represented\": \"WEST PHOENIX\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0022\",\n",
      "        \"value_represented\": \"GRAND AVE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1003\",\n",
      "        \"value_represented\": \"MESA\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1004\",\n",
      "        \"value_represented\": \"NORTH PHOENIX\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"1010\",\n",
      "        \"value_represented\": \"FALCON FIELD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"2001\",\n",
      "        \"value_represented\": \"GLENDALE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"2004\",\n",
      "        \"value_represented\": \"North Scottsdale\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"2005\",\n",
      "        \"value_represented\": \"PINNACLE PEAK\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"3002\",\n",
      "        \"value_represented\": \"CENTRAL PHOENIX\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"3003\",\n",
      "        \"value_represented\": \"SOUTH SCOTTSDALE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"3004\",\n",
      "        \"value_represented\": \"NATIONAL GUARD HQ-CO DEPT OF EMERGENCY MANAGEMENT-N 52ND & MCDOWELL\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"3005\",\n",
      "        \"value_represented\": \"WATER TREATMENT PLANT-LINDSEY RD NEAR GUADALUPE RD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"3006\",\n",
      "        \"value_represented\": \"MARYVALE-POLICE STN-ENCANTO BLVD NEAR 59TH AVE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"3007\",\n",
      "        \"value_represented\": \"SALT RIVER SERVICE CENTER-CITY EQUIPMENT SERVICE YARD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"3009\",\n",
      "        \"value_represented\": \"WEST CHANDLER-FIRE STN-PRICE RD & CHANDLER BLVD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"3010\",\n",
      "        \"value_represented\": \"GREENWOOD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4003\",\n",
      "        \"value_represented\": \"SOUTH PHOENIX\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4004\",\n",
      "        \"value_represented\": \"WEST CHANDLER\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4005\",\n",
      "        \"value_represented\": \"TEMPE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4006\",\n",
      "        \"value_represented\": \"HIGLEY\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4007\",\n",
      "        \"value_represented\": \"SEASONAL SITE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4008\",\n",
      "        \"value_represented\": \"CAVE CREEK\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4009\",\n",
      "        \"value_represented\": \"WEST 43RD AVENUE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4010\",\n",
      "        \"value_represented\": \"DYSART\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4011\",\n",
      "        \"value_represented\": \"BUCKEYE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4014\",\n",
      "        \"value_represented\": \"COYOTE LAKES\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4015\",\n",
      "        \"value_represented\": \"FISHER #1\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4016\",\n",
      "        \"value_represented\": \"Zuni Hills\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4018\",\n",
      "        \"value_represented\": \"Deer Valley\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4019\",\n",
      "        \"value_represented\": \"Diablo\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4020\",\n",
      "        \"value_represented\": \"Thirty-Third\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"4021\",\n",
      "        \"value_represented\": \"Eastwood\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"5100\",\n",
      "        \"value_represented\": \"Fort McDowell/Yuma Frank\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"7003\",\n",
      "        \"value_represented\": \"St Johns Air Monitoring Site\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"7020\",\n",
      "        \"value_represented\": \"Senior Center Air Monitoring Station\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"7021\",\n",
      "        \"value_represented\": \"Red Mountain Air Monitoring Station\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"7022\",\n",
      "        \"value_represented\": \"Lehi Air Monitoring Station\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"7024\",\n",
      "        \"value_represented\": \"High School Air Monitoring Station\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"8005\",\n",
      "        \"value_represented\": \"ESTRELLA PM2.5 1 HOUR NEPH\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"8006\",\n",
      "        \"value_represented\": \"BETHUNE ELEMENTARY SCHOOL\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9508\",\n",
      "        \"value_represented\": \"HUMBOLDT MOUNTAIN\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9604\",\n",
      "        \"value_represented\": \"ARROWHEAD-FIRE STN-DEER VALLEY RD NEAR 67TH AVE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9612\",\n",
      "        \"value_represented\": \"WICKENBURG SHERIFF STATION\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9701\",\n",
      "        \"value_represented\": \"MOUNT ORD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9702\",\n",
      "        \"value_represented\": \"BLUE POINT-SHERIFF STATION-TONTO NF-SALT RIVER RECREATION AREA\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9704\",\n",
      "        \"value_represented\": \"FOUNTAIN HILLS\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9706\",\n",
      "        \"value_represented\": \"RIO VERDE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9707\",\n",
      "        \"value_represented\": \"ROOSEVELT LAKE-SRP VACATION RESORT-LAKESIDE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9805\",\n",
      "        \"value_represented\": \"DESERT OUTDOR CENTER\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9812\",\n",
      "        \"value_represented\": \"DURANGO COMPLEX\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9990\",\n",
      "        \"value_represented\": \"TEMPE COMMUNITY CENTER\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9991\",\n",
      "        \"value_represented\": \"MAGNET TRADITIONAL SCHOOL\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9992\",\n",
      "        \"value_represented\": \"DESERT WEST\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9993\",\n",
      "        \"value_represented\": \"PALO VERDE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9994\",\n",
      "        \"value_represented\": \"SALT RIVER PIMA - MARICOPA ADMINISTRATION COMPLEX\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9995\",\n",
      "        \"value_represented\": \"PAPAGO PARK\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9996\",\n",
      "        \"value_represented\": \"PIONEER FORD\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9997\",\n",
      "        \"value_represented\": \"JLG SUPERSITE\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"9998\",\n",
      "        \"value_represented\": \"VEHICLE EMISSIONS LABORATORY\"\n",
      "    }\n",
      "]\n",
      "Number of non-null 'value_represented' results: 62\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  This list request should give us a list of all the monitoring stations in the county specified by the\n",
    "#  given city selected from the CITY_LOCATIONS dictionary\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['state'] = CITY_LOCATIONS['Mesa']['fips'][:2]   # the first two digits (characters) of FIPS is the state code\n",
    "request_data['county'] = CITY_LOCATIONS['Mesa']['fips'][2:]  # the last three digits (characters) of FIPS is the county code\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_SITES)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    non_null_results = [item for item in response['Data'] if item.get('value_represented') is not None]\n",
    "\n",
    "    # Print the filtered list and its length\n",
    "    print(json.dumps(non_null_results, indent=4))\n",
    "    print(\"Number of non-null 'value_represented' results:\", len(non_null_results))\n",
    "    #print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRnRPbZz_VCO"
   },
   "source": [
    "\n",
    "The above response gives us a list of monitoring stations in the Maricopa county. Each monitoring station has a unique \"code\" which is a string number, and, sometimes, a description. The description seems to be something about where the monitoring station is located.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjdKaLO4_VCO"
   },
   "source": [
    "**Step 3:** Making a daily summary request\n",
    "\n",
    "The function below is designed to encapsulate requests to the EPA AQS API. When calling the function one should create/copy a parameter template, then initialize that template with values that won't change with each call. Then on each call simply pass in the parameters that need to change, like date ranges.\n",
    "\n",
    "Another function below provides an example of extracting values and restructuring the response to make it a little more usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TGQ1BZhT_VCO"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the daily summary request. Daily summary provides a daily summary value for each sensor being requested\n",
    "#    from the start date to the end date.\n",
    "#\n",
    "#    Like the two other functions, this can be called with a mixture of a defined parameter dictionary, or with function\n",
    "#    parameters. If function parameters are provided, those take precedence over any parameters from the request template.\n",
    "#\n",
    "def request_daily_summary(email_address = None, key = None, param=None,\n",
    "                          begin_date = None, end_date = None, fips = None,\n",
    "                          endpoint_url = API_REQUEST_URL,\n",
    "                          endpoint_action = API_ACTION_DAILY_SUMMARY_COUNTY,\n",
    "                          request_template = AQS_REQUEST_TEMPLATE,\n",
    "                          headers = None):\n",
    "\n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    if param:\n",
    "        request_template['param'] = param\n",
    "    if begin_date:\n",
    "        request_template['begin_date'] = begin_date\n",
    "    if end_date:\n",
    "        request_template['end_date'] = end_date\n",
    "    if fips and len(fips)==5:\n",
    "        request_template['state'] = fips[:2]\n",
    "        request_template['county'] = fips[2:]\n",
    "\n",
    "    # Make sure there are values that allow us to make a call - these are always required\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_daily_summary()'\")\n",
    "    if not request_template['key']:\n",
    "        raise Exception(\"Must supply a key to call 'request_daily_summary()'\")\n",
    "    if not request_template['param']:\n",
    "        raise Exception(\"Must supply param values to call 'request_daily_summary()'\")\n",
    "    if not request_template['begin_date']:\n",
    "        raise Exception(\"Must supply a begin_date to call 'request_daily_summary()'\")\n",
    "    if not request_template['end_date']:\n",
    "        raise Exception(\"Must supply an end_date to call 'request_daily_summary()'\")\n",
    "    # Note we're not validating FIPS fields because not all of the daily summary actions require the FIPS numbers\n",
    "\n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SMkXu5i_VCO",
    "outputId": "293214f6-84c1-4371-8aa8-20bec890ccf3",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for the gaseous pollutants ...\n",
      "{\n",
      "    \"Header\": [\n",
      "        {\n",
      "            \"status\": \"Failed\",\n",
      "            \"request_time\": \"2024-10-30T21:54:37.823-04:00\",\n",
      "            \"url\": \"https://aqs.epa.gov/data/api/dailyData/byCounty?email=gmihir@uw.edu&key=mauvemouse74&param=42101,42401,42602,44201&bdate=19640501&edate=20241031&state=04&county=013\",\n",
      "            \"error\": [\n",
      "                \"bdate: 19640501, edate: 20241031, only 1 year of data is permitted.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Response for the particulate pollutants ...\n",
      "{\n",
      "    \"Header\": [\n",
      "        {\n",
      "            \"status\": \"Failed\",\n",
      "            \"request_time\": \"2024-10-30T21:54:38.651-04:00\",\n",
      "            \"url\": \"https://aqs.epa.gov/data/api/dailyData/byCounty?email=gmihir@uw.edu&key=mauvemouse74&param=81102,88101,88502&bdate=19640501&edate=20241031&state=04&county=013\",\n",
      "            \"error\": [\n",
      "                \"bdate: 19640501, edate: 20241031, only 1 year of data is permitted.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "request_data['state'] = CITY_LOCATIONS['Mesa']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['Mesa']['fips'][2:]\n",
    "\n",
    "# request daily summary data for May 01, 1964 to October 31st 2024 (the last 60 years). We put May and October based on the fire season\n",
    "gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=\"19640501\", end_date=\"20241031\")\n",
    "print(\"Response for the gaseous pollutants ...\")\n",
    "#\n",
    "if gaseous_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(gaseous_aqi['Data'],indent=4))\n",
    "elif gaseous_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "    print(\"Looks like the response generated no data. You might take a closer look at your request and the response data.\")\n",
    "else:\n",
    "    print(json.dumps(gaseous_aqi,indent=4))\n",
    "\n",
    "request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "# request daily summary data for the month of July in 2021\n",
    "particulate_aqi = request_daily_summary(request_template=request_data, begin_date=\"19640501\", end_date=\"20241031\")\n",
    "print(\"Response for the particulate pollutants ...\")\n",
    "#\n",
    "if particulate_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(particulate_aqi['Data'],indent=4))\n",
    "elif particulate_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "    print(\"Looks like the response generated no data. You might take a closer look at your request and the response data.\")\n",
    "else:\n",
    "    print(json.dumps(particulate_aqi,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran a single request to get data for all the required years, the API responded with a status failed. It said that I can only request data for the maximum of 1 year at a time. This led me to create a loop that would provide the API with the specific time period involving the fire season for each of the required years (1964-2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66wErZA4SMQB",
    "outputId": "fcca992e-831a-4777-fa9e-9830cca17b12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for gaseous pollutants in 1964.\n",
      "No data for particulate pollutants in 1964.\n",
      "No data for particulate pollutants in 1965.\n",
      "No data for particulate pollutants in 1966.\n",
      "No data for particulate pollutants in 1967.\n",
      "No data for particulate pollutants in 1968.\n",
      "No data for particulate pollutants in 1969.\n",
      "No data for particulate pollutants in 1970.\n",
      "No data for particulate pollutants in 1971.\n",
      "No data for particulate pollutants in 1972.\n",
      "No data for particulate pollutants in 1973.\n",
      "No data for particulate pollutants in 1974.\n",
      "No data for particulate pollutants in 1975.\n",
      "No data for particulate pollutants in 1976.\n",
      "No data for particulate pollutants in 1977.\n",
      "No data for particulate pollutants in 1978.\n",
      "No data for particulate pollutants in 1979.\n",
      "No data for particulate pollutants in 1980.\n",
      "No data for particulate pollutants in 1981.\n",
      "No data for particulate pollutants in 1982.\n",
      "No data for particulate pollutants in 1983.\n",
      "No data for particulate pollutants in 1984.\n",
      "No data for particulate pollutants in 1985.\n",
      "No data for particulate pollutants in 1987.\n"
     ]
    }
   ],
   "source": [
    "# Attribution: The code below has taken references from the professors code.\n",
    "\n",
    "# Helper function to format date for API\n",
    "def get_date_str(year, month_day):\n",
    "    return f\"{year}{month_day}\"\n",
    "\n",
    "gaseous_data = []\n",
    "particulate_data = []\n",
    "\n",
    "# We define the start and end years\n",
    "start_year = 1964\n",
    "end_year = 2024\n",
    "\n",
    "# In this loop, we go through the fire season of each year and request the API for that data\n",
    "for year in range(start_year, end_year + 1):\n",
    "    # Ensure that the begin date corresponds to May 1, and end to Oct 31 (fire season)\n",
    "    begin_date = get_date_str(year, \"0501\")\n",
    "    end_date = get_date_str(year, \"1031\")\n",
    "\n",
    "    # First we request the api for gaseous pollutants data\n",
    "    request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "    gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "\n",
    "    # Confirm status and accumulate data\n",
    "    if gaseous_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        gaseous_data.extend(gaseous_aqi['Data'])\n",
    "    elif gaseous_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(f\"No data for gaseous pollutants in {year}.\")\n",
    "    else:\n",
    "        print(json.dumps(gaseous_aqi, indent=4))\n",
    "\n",
    "    # Next we request the api for pollutants data\n",
    "    request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "    particulate_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "\n",
    "    # Confirm status and accumulate data\n",
    "    if particulate_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        particulate_data.extend(particulate_aqi['Data'])\n",
    "    elif particulate_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(f\"No data for particulate pollutants in {year}.\")\n",
    "    else:\n",
    "        print(json.dumps(particulate_aqi, indent=4))\n",
    "\n",
    "# The function below helps us save the data to a csv file for both the gaseous and particulate pollutants\n",
    "def save_to_csv(data, filename):\n",
    "    if data:\n",
    "        keys = data[0].keys()\n",
    "        with open(filename, \"w\", newline=\"\") as csv_file:\n",
    "            dict_writer = csv.DictWriter(csv_file, fieldnames=keys)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(data)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "    else:\n",
    "        print(f\"No data to save for {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ../Processed Data/gaseous_pollutants.csv\n",
      "Data saved to ../Processed Data/particulate_pollutants.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "save_to_csv(gaseous_data, \"../Processed Data/gaseous_pollutants.csv\")\n",
    "save_to_csv(particulate_data, \"../Processed Data/particulate_pollutants.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process AQI Data\n",
    "\n",
    "Now, that the data is collected for the required time interval, I process the data by removing any null aqi values. Then I combine both the gaseous_pollutants and the particulate_pollutants together to understand how much data I have. Based on the data, I believe I have sufficient inforamtion to calculate the average AQI for the day/month/year so I perform that calculation by taking the average. Finally, I save the processed data in AQI_data.csv which will be used for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I read the gaseous_pollutants and particulate_pollutants data and see if they have similar columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tBdASKopXppK",
    "outputId": "b7c30f38-3855-49b5-fa74-17401eb2cd8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in gaseous_df: ['state_code', 'county_code', 'site_number', 'parameter_code', 'poc', 'latitude', 'longitude', 'datum', 'parameter', 'sample_duration_code', 'sample_duration', 'pollutant_standard', 'date_local', 'units_of_measure', 'event_type', 'observation_count', 'observation_percent', 'validity_indicator', 'arithmetic_mean', 'first_max_value', 'first_max_hour', 'aqi', 'method_code', 'method', 'local_site_name', 'site_address', 'state', 'county', 'city', 'cbsa_code', 'cbsa', 'date_of_last_change']\n",
      "Columns in particulate_df: ['state_code', 'county_code', 'site_number', 'parameter_code', 'poc', 'latitude', 'longitude', 'datum', 'parameter', 'sample_duration_code', 'sample_duration', 'pollutant_standard', 'date_local', 'units_of_measure', 'event_type', 'observation_count', 'observation_percent', 'validity_indicator', 'arithmetic_mean', 'first_max_value', 'first_max_hour', 'aqi', 'method_code', 'method', 'local_site_name', 'site_address', 'state', 'county', 'city', 'cbsa_code', 'cbsa', 'date_of_last_change']\n"
     ]
    }
   ],
   "source": [
    "gaseous_df = pd.read_csv(\"./Processed Data/gaseous_pollutants.csv\")\n",
    "particulate_df = pd.read_csv(\"./Processed Data/particulate_pollutants.csv\")\n",
    "\n",
    "print(\"Columns in gaseous_df:\", gaseous_df.columns.tolist())\n",
    "print(\"Columns in particulate_df:\", particulate_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output above, both the dataframes have similar columns.\n",
    "\n",
    "Now, I explore the different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nV632H7KcQF6",
    "outputId": "c52ba6ee-10d4-4bdf-acb7-faebe1adf8c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics - gaseous_df\n",
      "       state_code  county_code    site_number  parameter_code            poc  \\\n",
      "count    864929.0     864929.0  864929.000000   864929.000000  864929.000000   \n",
      "mean          4.0         13.0    4157.067377    43574.674844       1.221315   \n",
      "std           0.0          0.0    3271.684067      900.169115       0.873470   \n",
      "min           4.0         13.0       3.000000    42101.000000       1.000000   \n",
      "25%           4.0         13.0    2001.000000    42602.000000       1.000000   \n",
      "50%           4.0         13.0    3003.000000    44201.000000       1.000000   \n",
      "75%           4.0         13.0    7020.000000    44201.000000       1.000000   \n",
      "max           4.0         13.0    9998.000000    44201.000000       6.000000   \n",
      "\n",
      "            latitude      longitude  observation_count  observation_percent  \\\n",
      "count  864929.000000  864929.000000      864929.000000        864929.000000   \n",
      "mean       33.507747    -112.009782          22.140232            99.231559   \n",
      "std         0.128005       0.211769          11.837659            21.059410   \n",
      "min        33.290229    -112.831103           1.000000             4.000000   \n",
      "25%        33.452440    -112.117480          22.000000           100.000000   \n",
      "50%        33.479680    -112.046590          24.000000           100.000000   \n",
      "75%        33.560310    -111.865360          24.000000           100.000000   \n",
      "max        33.982800    -111.150401         288.000000           900.000000   \n",
      "\n",
      "       arithmetic_mean  first_max_value  first_max_hour            aqi  \\\n",
      "count    864929.000000    864929.000000   864929.000000  613826.000000   \n",
      "mean          1.697243         3.606496       11.074272      48.597101   \n",
      "std           7.572952        29.592992        5.516327      30.866268   \n",
      "min          -0.200000        -0.200000        0.000000       0.000000   \n",
      "25%           0.032235         0.050000        9.000000      31.000000   \n",
      "50%           0.043294         0.063000       11.000000      45.000000   \n",
      "75%           0.350000         0.700000       13.000000      64.000000   \n",
      "max        3166.650000     17000.000000       23.000000     394.000000   \n",
      "\n",
      "         method_code  cbsa_code  \n",
      "count  864910.000000   864929.0  \n",
      "mean       71.489641    38060.0  \n",
      "std        76.292581        0.0  \n",
      "min        11.000000    38060.0  \n",
      "25%        47.000000    38060.0  \n",
      "50%        74.000000    38060.0  \n",
      "75%        87.000000    38060.0  \n",
      "max       600.000000    38060.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Basic statistics - gaseous_df\")\n",
    "print(gaseous_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hn0ydiv2cTK9",
    "outputId": "61b45a3e-cc76-4be3-c43f-11fd90d78fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics - particulate_df\n",
      "       state_code  county_code    site_number  parameter_code            poc  \\\n",
      "count    375551.0     375551.0  375551.000000   375551.000000  375551.000000   \n",
      "mean          4.0         13.0    4533.737410    85644.735727       2.261632   \n",
      "std           0.0          0.0    3482.777929     3344.745421       1.073024   \n",
      "min           4.0         13.0      13.000000    81102.000000       1.000000   \n",
      "25%           4.0         13.0    1004.000000    81102.000000       1.000000   \n",
      "50%           4.0         13.0    4005.000000    88101.000000       3.000000   \n",
      "75%           4.0         13.0    7022.000000    88101.000000       3.000000   \n",
      "max           4.0         13.0    9998.000000    88502.000000       9.000000   \n",
      "\n",
      "            latitude      longitude  observation_count  observation_percent  \\\n",
      "count  375551.000000  375551.000000      375551.000000        375551.000000   \n",
      "mean       33.466012    -112.061539           6.009333           101.931455   \n",
      "std         0.077059       0.150797           9.384663            43.471038   \n",
      "min        33.287828    -112.831103           1.000000             4.000000   \n",
      "25%        33.410180    -112.142560           1.000000           100.000000   \n",
      "50%        33.476111    -112.095767           1.000000           100.000000   \n",
      "75%        33.503833    -111.934710           1.000000           100.000000   \n",
      "max        33.970308    -111.676928          25.000000          2500.000000   \n",
      "\n",
      "       arithmetic_mean  first_max_value  first_max_hour            aqi  \\\n",
      "count    375551.000000    375551.000000   375551.000000  292490.000000   \n",
      "mean         17.929644        34.763412        6.317091      36.644419   \n",
      "std          22.483237       129.135596        9.435325      15.098229   \n",
      "min          -3.000000        -3.000000        0.000000       0.000000   \n",
      "25%           5.800000         6.000000        0.000000      27.000000   \n",
      "50%           8.575000         9.200000        0.000000      35.000000   \n",
      "75%          24.000000        31.000000       15.000000      46.000000   \n",
      "max         759.600000      8540.000000       23.000000     450.000000   \n",
      "\n",
      "         method_code  cbsa_code  \n",
      "count  375551.000000   375551.0  \n",
      "mean      153.619761    38060.0  \n",
      "std        81.591371        0.0  \n",
      "min        52.000000    38060.0  \n",
      "25%        79.000000    38060.0  \n",
      "50%       170.000000    38060.0  \n",
      "75%       182.000000    38060.0  \n",
      "max       830.000000    38060.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Basic statistics - particulate_df\")\n",
    "print(particulate_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output above, both the dataframes do have a lot of null values in their aqi columns, so I decide to explore further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9kPBWMpcMnC",
    "outputId": "e3a71b3d-504d-4c8d-914e-99cfe0e10d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in gaseous_df: 864929\n",
      "Null values in 'aqi' column of gaseous_df: 251103\n",
      "Percentage of nulls in 'aqi' column of gaseous_df: 29.03163149807672\n",
      "-------------------------------------------------------------------------------------\n",
      "Total records in particulate_df: 375551\n",
      "Null values in 'aqi' column of particulate_df: 83061\n",
      "Percentage of nulls in 'aqi' column of particulate_df: 22.117102603907327\n"
     ]
    }
   ],
   "source": [
    "# Total number of records and percentage of nulls in 'aqi' for each dataframe\n",
    "def analyze_aqi(df):\n",
    "  total_records = len(df)\n",
    "  null_count = df['aqi'].isnull().sum()\n",
    "  percentage_nulls = (null_count / total_records) * 100 if total_records > 0 else 0\n",
    "  return total_records, null_count, percentage_nulls\n",
    "\n",
    "gaseous_total_records, gaseous_null_records, gaseous_percentage_nulls = analyze_aqi(gaseous_df)\n",
    "particulate_total_records, particulate_null_records, particulate_percentage_nulls = analyze_aqi(particulate_df)\n",
    "\n",
    "print(\"Total records in gaseous_df:\", gaseous_total_records)\n",
    "print(\"Null values in 'aqi' column of gaseous_df:\", gaseous_null_records)\n",
    "print(\"Percentage of nulls in 'aqi' column of gaseous_df:\", gaseous_percentage_nulls)\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Total records in particulate_df:\", particulate_total_records)\n",
    "print(\"Null values in 'aqi' column of particulate_df:\", particulate_null_records)\n",
    "print(\"Percentage of nulls in 'aqi' column of particulate_df:\", particulate_percentage_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above output, I think that I have enough data to reasonably make an estimate for the avg aqis. Therefore, I drop the NaN values and combine both the pollutants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zIcH8wJJeFCW",
    "outputId": "03b5fdaf-9648-452a-f43a-0b6e072a86d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>site_number</th>\n",
       "      <th>parameter_code</th>\n",
       "      <th>poc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datum</th>\n",
       "      <th>parameter</th>\n",
       "      <th>sample_duration_code</th>\n",
       "      <th>...</th>\n",
       "      <th>method_code</th>\n",
       "      <th>method</th>\n",
       "      <th>local_site_name</th>\n",
       "      <th>site_address</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>city</th>\n",
       "      <th>cbsa_code</th>\n",
       "      <th>cbsa</th>\n",
       "      <th>date_of_last_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3002</td>\n",
       "      <td>42401</td>\n",
       "      <td>3</td>\n",
       "      <td>33.457970</td>\n",
       "      <td>-112.046590</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Sulfur dioxide</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>INSTRUMENTAL - CONDUCTIMETRIC</td>\n",
       "      <td>CENTRAL PHOENIX</td>\n",
       "      <td>1645 E ROOSEVELT ST-CENTRAL PHOENIX STN</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>38060</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>2013-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3002</td>\n",
       "      <td>42401</td>\n",
       "      <td>3</td>\n",
       "      <td>33.457970</td>\n",
       "      <td>-112.046590</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Sulfur dioxide</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>INSTRUMENTAL - CONDUCTIMETRIC</td>\n",
       "      <td>CENTRAL PHOENIX</td>\n",
       "      <td>1645 E ROOSEVELT ST-CENTRAL PHOENIX STN</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>38060</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>2013-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3002</td>\n",
       "      <td>42401</td>\n",
       "      <td>3</td>\n",
       "      <td>33.457970</td>\n",
       "      <td>-112.046590</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Sulfur dioxide</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>INSTRUMENTAL - CONDUCTIMETRIC</td>\n",
       "      <td>CENTRAL PHOENIX</td>\n",
       "      <td>1645 E ROOSEVELT ST-CENTRAL PHOENIX STN</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>38060</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>2013-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3002</td>\n",
       "      <td>42401</td>\n",
       "      <td>3</td>\n",
       "      <td>33.457970</td>\n",
       "      <td>-112.046590</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Sulfur dioxide</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>INSTRUMENTAL - CONDUCTIMETRIC</td>\n",
       "      <td>CENTRAL PHOENIX</td>\n",
       "      <td>1645 E ROOSEVELT ST-CENTRAL PHOENIX STN</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>38060</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>2013-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3002</td>\n",
       "      <td>42401</td>\n",
       "      <td>3</td>\n",
       "      <td>33.457970</td>\n",
       "      <td>-112.046590</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>Sulfur dioxide</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>INSTRUMENTAL - CONDUCTIMETRIC</td>\n",
       "      <td>CENTRAL PHOENIX</td>\n",
       "      <td>1645 E ROOSEVELT ST-CENTRAL PHOENIX STN</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>38060</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>2013-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895209</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>9997</td>\n",
       "      <td>88101</td>\n",
       "      <td>3</td>\n",
       "      <td>33.503833</td>\n",
       "      <td>-112.095767</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>638.0</td>\n",
       "      <td>Teledyne T640X at 16.67 LPM w/Network Data Ali...</td>\n",
       "      <td>JLG SUPERSITE</td>\n",
       "      <td>4530 N 17TH AVENUE</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>38060</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>2024-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895210</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>9997</td>\n",
       "      <td>88101</td>\n",
       "      <td>3</td>\n",
       "      <td>33.503833</td>\n",
       "      <td>-112.095767</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>638.0</td>\n",
       "      <td>Teledyne T640X at 16.67 LPM w/Network Data Ali...</td>\n",
       "      <td>JLG SUPERSITE</td>\n",
       "      <td>4530 N 17TH AVENUE</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>38060</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>2024-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895211</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>9997</td>\n",
       "      <td>88101</td>\n",
       "      <td>3</td>\n",
       "      <td>33.503833</td>\n",
       "      <td>-112.095767</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>638.0</td>\n",
       "      <td>Teledyne T640X at 16.67 LPM w/Network Data Ali...</td>\n",
       "      <td>JLG SUPERSITE</td>\n",
       "      <td>4530 N 17TH AVENUE</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>38060</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>2024-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895212</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>9997</td>\n",
       "      <td>88101</td>\n",
       "      <td>3</td>\n",
       "      <td>33.503833</td>\n",
       "      <td>-112.095767</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>638.0</td>\n",
       "      <td>Teledyne T640X at 16.67 LPM w/Network Data Ali...</td>\n",
       "      <td>JLG SUPERSITE</td>\n",
       "      <td>4530 N 17TH AVENUE</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>38060</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>2024-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895213</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>9997</td>\n",
       "      <td>88101</td>\n",
       "      <td>3</td>\n",
       "      <td>33.503833</td>\n",
       "      <td>-112.095767</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>PM2.5 - Local Conditions</td>\n",
       "      <td>X</td>\n",
       "      <td>...</td>\n",
       "      <td>638.0</td>\n",
       "      <td>Teledyne T640X at 16.67 LPM w/Network Data Ali...</td>\n",
       "      <td>JLG SUPERSITE</td>\n",
       "      <td>4530 N 17TH AVENUE</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>38060</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>2024-10-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>895214 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state_code  county_code  site_number  parameter_code  poc   latitude  \\\n",
       "0                4           13         3002           42401    3  33.457970   \n",
       "1                4           13         3002           42401    3  33.457970   \n",
       "2                4           13         3002           42401    3  33.457970   \n",
       "3                4           13         3002           42401    3  33.457970   \n",
       "4                4           13         3002           42401    3  33.457970   \n",
       "...            ...          ...          ...             ...  ...        ...   \n",
       "895209           4           13         9997           88101    3  33.503833   \n",
       "895210           4           13         9997           88101    3  33.503833   \n",
       "895211           4           13         9997           88101    3  33.503833   \n",
       "895212           4           13         9997           88101    3  33.503833   \n",
       "895213           4           13         9997           88101    3  33.503833   \n",
       "\n",
       "         longitude  datum                 parameter sample_duration_code  ...  \\\n",
       "0      -112.046590  NAD83            Sulfur dioxide                    1  ...   \n",
       "1      -112.046590  NAD83            Sulfur dioxide                    1  ...   \n",
       "2      -112.046590  NAD83            Sulfur dioxide                    1  ...   \n",
       "3      -112.046590  NAD83            Sulfur dioxide                    1  ...   \n",
       "4      -112.046590  NAD83            Sulfur dioxide                    1  ...   \n",
       "...            ...    ...                       ...                  ...  ...   \n",
       "895209 -112.095767  WGS84  PM2.5 - Local Conditions                    X  ...   \n",
       "895210 -112.095767  WGS84  PM2.5 - Local Conditions                    X  ...   \n",
       "895211 -112.095767  WGS84  PM2.5 - Local Conditions                    X  ...   \n",
       "895212 -112.095767  WGS84  PM2.5 - Local Conditions                    X  ...   \n",
       "895213 -112.095767  WGS84  PM2.5 - Local Conditions                    X  ...   \n",
       "\n",
       "       method_code                                             method  \\\n",
       "0             13.0                      INSTRUMENTAL - CONDUCTIMETRIC   \n",
       "1             13.0                      INSTRUMENTAL - CONDUCTIMETRIC   \n",
       "2             13.0                      INSTRUMENTAL - CONDUCTIMETRIC   \n",
       "3             13.0                      INSTRUMENTAL - CONDUCTIMETRIC   \n",
       "4             13.0                      INSTRUMENTAL - CONDUCTIMETRIC   \n",
       "...            ...                                                ...   \n",
       "895209       638.0  Teledyne T640X at 16.67 LPM w/Network Data Ali...   \n",
       "895210       638.0  Teledyne T640X at 16.67 LPM w/Network Data Ali...   \n",
       "895211       638.0  Teledyne T640X at 16.67 LPM w/Network Data Ali...   \n",
       "895212       638.0  Teledyne T640X at 16.67 LPM w/Network Data Ali...   \n",
       "895213       638.0  Teledyne T640X at 16.67 LPM w/Network Data Ali...   \n",
       "\n",
       "        local_site_name                             site_address    state  \\\n",
       "0       CENTRAL PHOENIX  1645 E ROOSEVELT ST-CENTRAL PHOENIX STN  Arizona   \n",
       "1       CENTRAL PHOENIX  1645 E ROOSEVELT ST-CENTRAL PHOENIX STN  Arizona   \n",
       "2       CENTRAL PHOENIX  1645 E ROOSEVELT ST-CENTRAL PHOENIX STN  Arizona   \n",
       "3       CENTRAL PHOENIX  1645 E ROOSEVELT ST-CENTRAL PHOENIX STN  Arizona   \n",
       "4       CENTRAL PHOENIX  1645 E ROOSEVELT ST-CENTRAL PHOENIX STN  Arizona   \n",
       "...                 ...                                      ...      ...   \n",
       "895209    JLG SUPERSITE                       4530 N 17TH AVENUE  Arizona   \n",
       "895210    JLG SUPERSITE                       4530 N 17TH AVENUE  Arizona   \n",
       "895211    JLG SUPERSITE                       4530 N 17TH AVENUE  Arizona   \n",
       "895212    JLG SUPERSITE                       4530 N 17TH AVENUE  Arizona   \n",
       "895213    JLG SUPERSITE                       4530 N 17TH AVENUE  Arizona   \n",
       "\n",
       "          county     city cbsa_code                         cbsa  \\\n",
       "0       Maricopa  Phoenix     38060  Phoenix-Mesa-Scottsdale, AZ   \n",
       "1       Maricopa  Phoenix     38060  Phoenix-Mesa-Scottsdale, AZ   \n",
       "2       Maricopa  Phoenix     38060  Phoenix-Mesa-Scottsdale, AZ   \n",
       "3       Maricopa  Phoenix     38060  Phoenix-Mesa-Scottsdale, AZ   \n",
       "4       Maricopa  Phoenix     38060  Phoenix-Mesa-Scottsdale, AZ   \n",
       "...          ...      ...       ...                          ...   \n",
       "895209  Maricopa  Phoenix     38060  Phoenix-Mesa-Scottsdale, AZ   \n",
       "895210  Maricopa  Phoenix     38060  Phoenix-Mesa-Scottsdale, AZ   \n",
       "895211  Maricopa  Phoenix     38060  Phoenix-Mesa-Scottsdale, AZ   \n",
       "895212  Maricopa  Phoenix     38060  Phoenix-Mesa-Scottsdale, AZ   \n",
       "895213  Maricopa  Phoenix     38060  Phoenix-Mesa-Scottsdale, AZ   \n",
       "\n",
       "        date_of_last_change  \n",
       "0                2013-06-11  \n",
       "1                2013-06-11  \n",
       "2                2013-06-11  \n",
       "3                2013-06-11  \n",
       "4                2013-06-11  \n",
       "...                     ...  \n",
       "895209           2024-10-17  \n",
       "895210           2024-10-17  \n",
       "895211           2024-10-17  \n",
       "895212           2024-10-17  \n",
       "895213           2024-10-17  \n",
       "\n",
       "[895214 rows x 32 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NaN values from both DataFrames\n",
    "gaseous_df_cleaned = gaseous_df.dropna()\n",
    "particulate_df_cleaned = particulate_df.dropna()\n",
    "\n",
    "# Concatenate the cleaned DataFrames\n",
    "combined_df = pd.concat([gaseous_df_cleaned, particulate_df_cleaned], ignore_index=True)\n",
    "\n",
    "# Ensure no duplicates exist\n",
    "combined_df_no_duplicates = combined_df.drop_duplicates()\n",
    "\n",
    "combined_df_no_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a cleaned combined dataframe, I calculate the average AQI's to help with the comparision of the smoke estimate.\n",
    "Note: I also calculate the monthly and daily avg aqi in case I need it for the future parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4msBIPfpenr-"
   },
   "outputs": [],
   "source": [
    "combined_df_no_duplicates['date_local'] = pd.to_datetime(combined_df_no_duplicates['date_local'])\n",
    "\n",
    "# Here I extract the year, month, and day\n",
    "combined_df_no_duplicates['year'] = combined_df_no_duplicates['date_local'].dt.year\n",
    "combined_df_no_duplicates['month'] = combined_df_no_duplicates['date_local'].dt.month\n",
    "combined_df_no_duplicates['day'] = combined_df_no_duplicates['date_local'].dt.day\n",
    "\n",
    "# Here I am calculating the daily average AQI\n",
    "daily_avg_aqi = combined_df_no_duplicates.groupby(['year', 'month', 'day'])['aqi'].mean().reset_index()\n",
    "daily_avg_aqi = daily_avg_aqi.rename(columns={'aqi': 'daily_avg_aqi'})\n",
    "\n",
    "# Here I am calculating the monthly average AQI\n",
    "monthly_avg_aqi = combined_df_no_duplicates.groupby(['year', 'month'])['aqi'].mean().reset_index()\n",
    "monthly_avg_aqi = monthly_avg_aqi.rename(columns={'aqi': 'monthly_avg_aqi'})\n",
    "\n",
    "# Here I am calculating the yearly average AQI\n",
    "yearly_avg_aqi = combined_df_no_duplicates.groupby(['year'])['aqi'].mean().reset_index()\n",
    "yearly_avg_aqi = yearly_avg_aqi.rename(columns={'aqi': 'yearly_avg_aqi'})\n",
    "\n",
    "# We merge the average AQI values back into the original DataFrame\n",
    "combined_df_no_duplicates = pd.merge(combined_df_no_duplicates, daily_avg_aqi, on=['year', 'month', 'day'], how='left')\n",
    "combined_df_no_duplicates = pd.merge(combined_df_no_duplicates, monthly_avg_aqi, on=['year', 'month'], how='left')\n",
    "combined_df_no_duplicates = pd.merge(combined_df_no_duplicates, yearly_avg_aqi, on=['year'], how='left')\n",
    "\n",
    "combined_df_no_duplicates.to_csv('./Processed Data/AQI_data.csv', index=False) # Save the final dataset"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
